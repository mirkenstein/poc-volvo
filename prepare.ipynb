{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaff5723-beee-445e-8838-35667da9e018",
   "metadata": {},
   "source": [
    "# Vector Search and RAG function application based on SuperDuperDB"
   ]
  },
  {
   "cell_type": "code",
   "id": "4134fa4c-f166-4e88-b44b-cb3e92b0c6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:14:39.381581Z",
     "start_time": "2024-09-06T16:14:34.304384Z"
    }
   },
   "source": [
    "import os\n",
    "import click\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sentence_transformers\n",
    "from dotenv import load_dotenv\n",
    "from superduper import (\n",
    "    Document,\n",
    "    Listener,\n",
    "    model,ObjectModel,\n",
    "    Schema,\n",
    "    VectorIndex,\n",
    "    superduper,\n",
    "    vector\n",
    ")\n",
    "# from superduper.backends.mongodb import\n",
    "import superduper_mongodb\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnm/PycharmProjects/poc-volvo/.venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "45bb7460-069d-4ab1-8781-7211b4a0258a",
   "metadata": {},
   "source": [
    "## Connect to mongodb database"
   ]
  },
  {
   "cell_type": "code",
   "id": "07e83996-c889-4596-9a27-487700412554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:14:39.403531Z",
     "start_time": "2024-09-06T16:14:39.383432Z"
    }
   },
   "source": [
    "mongodb_uri = os.getenv(\"MONGODB_URI\", \"superduperdb-demo\")\n",
    "artifact_store = os.getenv(\"ARTIFACT_STORE\", \"data/artifact_store\")\n",
    "\n",
    "db = superduper(mongodb_uri, artifact_store=f\"filesystem://{artifact_store}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Sep-06 11:14:39.39| INFO     | localhost.localdomain| superduper.base.build:56   | Data Client is ready. MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\n",
      "2024-Sep-06 11:14:39.39| INFO     | localhost.localdomain| superduper.base.build:35   | Connecting to Metadata Client with engine:  MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\n",
      "2024-Sep-06 11:14:39.40| INFO     | localhost.localdomain| superduper.base.build:141  | Connecting to compute client: Compute(uri=None, compute_kwargs={}, _path='superduper.backends.local.compute.LocalComputeBackend')\n",
      "2024-Sep-06 11:14:39.40| INFO     | localhost.localdomain| superduper.base.datalayer:106  | Building Data Layer\n",
      "2024-Sep-06 11:14:39.40| INFO     | localhost.localdomain| superduper.base.build:208  | Configuration: \n",
      " +----------------+---------------------------------------+\n",
      "| Configuration  |                 Value                 |\n",
      "+----------------+---------------------------------------+\n",
      "|  Data Backend  |  mongodb://localhost:27017/volvo-app  |\n",
      "| Artifact Store | filesystem://data/volvo-app/artifacts |\n",
      "+----------------+---------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "00e41b23-247d-43fa-ac8b-3f4a28b0ff4c",
   "metadata": {},
   "source": "## Parse pdf files and store them in the database"
  },
  {
   "cell_type": "code",
   "id": "7e6c63e3-8a28-48e6-940a-a5e4bf8e24da",
   "metadata": {},
   "source": [
    "from superduper.ext.unstructured.encoder import unstructured_encoder\n",
    "\n",
    "db.apply(unstructured_encoder)\n",
    "\n",
    "pdf_folder = 'pdf-folders'\n",
    "\n",
    "pdf_paths = [os.path.join(pdf_folder, pdf) for pdf in os.listdir(pdf_folder)]\n",
    "# collection = superduper_mongodb(\"source\")\n",
    "to_insert = [\n",
    "    Document({\"elements\": unstructured_encoder(pdf_path)}) for pdf_path in pdf_paths\n",
    "]\n",
    "# db.execute(collection.insert_many(to_insert))\n",
    "# _ = db['source'].insert_many(to_insert).execute()\n",
    "db['source'].insert_many(to_insert).execute()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db.show()",
   "id": "537828a217426d11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db['source'].find_one().execute().unpack()",
   "id": "8109d7c8b2e43da8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5fc5d0eb-8b85-4f50-a6fb-951932d5e09b",
   "metadata": {},
   "source": [
    "## Create a chunking model to chunk pdf chunks"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def merge_metadatas(metadatas, return_center=False):\n",
    "    MAX_NUM = 999999999\n",
    "    if not metadatas:\n",
    "        return {}\n",
    "    p1, p2, p3, p4 = (MAX_NUM, MAX_NUM), (MAX_NUM, 0), (0, 0), (0, MAX_NUM)\n",
    "    for metadata in metadatas:\n",
    "        p1_, p2_, p3_, p4_ = metadata[\"coordinates\"][\"points\"]\n",
    "        p1 = (min(p1[0], p1_[0]), min(p1[1], p1_[1]))\n",
    "        p2 = (min(p2[0], p2_[0]), max(p2[1], p2_[1]))\n",
    "        p3 = (max(p3[0], p3_[0]), max(p3[1], p3_[1]))\n",
    "        p4 = (max(p4[0], p4_[0]), min(p4[1], p4_[1]))\n",
    "    points = (p1, p2, p3, p4)\n",
    "    if return_center:\n",
    "        points = {\"x\": (p1[0] + p3[0]) / 2, \"y\": (p1[1] + p3[1]) / 2}\n",
    "        page_number = metadata[\"page_number\"]\n",
    "    return {\"points\": points, \"page_number\": page_number}\n",
    "\n",
    "\n",
    "def create_chunk_and_metadatas(page_elements, stride=3, window=10):\n",
    "    datas = []\n",
    "    for i in range(0, len(page_elements), stride):\n",
    "        windown_elements = page_elements[i : i + window]\n",
    "        metadatas = [e.metadata.to_dict() for e in windown_elements]\n",
    "        chunk = \"\\n\".join([e.text for e in windown_elements])\n",
    "        datas.append(\n",
    "            {\"txt\": chunk, \"metadata\": merge_metadatas(metadatas, return_center=True)}\n",
    "        )\n",
    "    return datas\n",
    "\n",
    "\n",
    "@model(flatten=True, model_update_kwargs={'document_embedded': False})\n",
    "def get_chunks(elements):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    pages_elements = defaultdict(list)\n",
    "    for element in elements:\n",
    "        pages_elements[element.metadata.page_number].append(element)\n",
    "\n",
    "    all_chunks_and_links = sum(\n",
    "        [\n",
    "            create_chunk_and_metadatas(page_elements)\n",
    "            for _, page_elements in pages_elements.items()\n",
    "        ],\n",
    "        [],\n",
    "    )\n",
    "    return all_chunks_and_links\n"
   ],
   "id": "ea1ca929-e6b5-494a-b6e1-f709995128ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODEL_IDENTIFIER_CHUNK = \"chunker\"\n",
    "upstream_listener= Listener(\n",
    "        model=get_chunks,\n",
    "        select=db['source'].select(),\n",
    "        key=\"elements\",\n",
    "       uuid=MODEL_IDENTIFIER_CHUNK\n",
    ")\n",
    "db.apply(upstream_listener)"
   ],
   "id": "1a2dbd9844007331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db.show()",
   "id": "d320a7bd2a1e6027",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db.databackend.db.list_collection_names() \n",
   "id": "49de90408d3d87f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "upstream_listener.outputs_key\n",
    "# '_outputs.chunker'"
   ],
   "id": "5eb8340f4cb12d39",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed4e6123-f8a8-46da-85c1-74882ec4cf7e",
   "metadata": {},
   "source": [
    "# MODEL_IDENTIFIER_CHUNK = \"chunk\"\n",
    "# from superduper import ObjectModel\n",
    "# chunk_model = ObjectModel(\n",
    "#     identifier=MODEL_IDENTIFIER_CHUNK,\n",
    "#     object=get_chunks,\n",
    "#     flatten=True,\n",
    "#     model_update_kwargs={\"document_embedded\": False},\n",
    "#     output_schema=Schema(identifier=\"myschema\", fields={\"txt\": \"string\"}),\n",
    "# )\n",
    "\n",
    "# db.add(\n",
    "#     Listener(\n",
    "#         model=chunk_model,\n",
    "#         select=select,\n",
    "#         key=\"elements\",\n",
    "#     )\n",
    "# )\n",
    "# upstream_listener= Listener(\n",
    "#         model=get_chunks,\n",
    "#         select=db['source'].find(),\n",
    "#         key=\"elements\",\n",
    "#        uuid=MODEL_IDENTIFIER_CHUNK\n",
    "# )\n",
    "# db.apply(upstream_listener)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af4df45f-c333-403b-8fcb-2bf972aeacc6",
   "metadata": {},
   "source": [
    "## Embedding all text blocks and building vector indexes"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SOURCE_KEY = \"elements\"\n",
    "MODEL_IDENTIFIER_EMBEDDING = \"embedding\"\n",
    "VECTOR_INDEX_IDENTIFIER = \"vector-index\"\n",
    "# COLLECTION_NAME_CHUNK = f\"_outputs.{SOURCE_KEY}.{MODEL_IDENTIFIER_CHUNK}\"\n",
    "COLLECTION_NAME_CHUNK = f\"_outputs.{MODEL_IDENTIFIER_CHUNK}\" # _outputs.chunk\n",
    "# CHUNK_OUTPUT_KEY = f\"_outputs.{SOURCE_KEY}.{MODEL_IDENTIFIER_CHUNK}\"\n",
    "CHUNK_OUTPUT_KEY = f\"_outputs.{MODEL_IDENTIFIER_CHUNK}.txt\"\n",
    "indexing_key = upstream_listener.outputs_key # Same as CHUNK_OUTPUT_KEY\n",
    "chunk_collection = db[COLLECTION_NAME_CHUNK]\n",
    "\n",
    "def preprocess(x):\n",
    "    if isinstance(x, dict):\n",
    "        # For model chains, the logic of this key needs to be optimized.\n",
    "        chunk = sorted(x.items())[-1][1]\n",
    "        return chunk[\"txt\"]\n",
    "    return x\n",
    "from superduper_sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\n",
    "    identifier=MODEL_IDENTIFIER_EMBEDDING,\n",
    "    object=sentence_transformers.SentenceTransformer(\"BAAI/bge-large-en-v1.5\", device=\"cuda\"),\n",
    "    datatype=vector(shape=(1024,)),\n",
    "    device=\"cuda\",\n",
    "    # predict_method=\"encode\",\n",
    "    # preprocess=preprocess,\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    # batch_predict=True,\n",
    "    predict_kwargs={\"show_progress_bar\": True},\n",
    "    # device='cuda'\n",
    "\n",
    ")\n",
    "# Create vector-index\n",
    "vector_index = \\\n",
    "    VectorIndex(\n",
    "        VECTOR_INDEX_IDENTIFIER,\n",
    "        indexing_listener=Listener(\n",
    "            select=chunk_collection.select(),\n",
    "            key=CHUNK_OUTPUT_KEY,  # Key for the documents\n",
    "            # key=indexing_key,  # Key for the documents\n",
    "            model=embedding_model,  # Specify the model for processing\n",
    "            # predict_kwargs={\"max_chunk_size\": 64},\n",
    "            uuid=\"embedding-bge-large\",\n",
    "            identifier=\"embedding-bge-large-listener\"\n",
    "        )\n",
    "    )\n",
    "# db.apply()"
   ],
   "id": "dd1b5849-a84b-4b7c-8261-5f62e0b30080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Start Indexing Embeddings",
   "id": "4d4704f7f68b74ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db.apply(vector_index)",
   "id": "7d68c9721a43cd7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(len(embedding_model.predict(\"What is superduper\")))",
   "id": "2d182e89fdbe26e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db.show()",
   "id": "ac3b394a458d79d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db[COLLECTION_NAME_CHUNK].find_one().execute().unpack()\n",
   "id": "db1160c2c3e248c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb739534-25f4-48b8-b626-fbbd3049ec9d",
   "metadata": {},
   "source": [
    "## Define a vector search function"
   ]
  },
  {
   "cell_type": "code",
   "id": "b32cfd64-3e75-418c-9a85-355d87ccb501",
   "metadata": {},
   "source": [
    "from pprint import pprint\n",
    "def vector_search(query, top_k=5):\n",
    "    collection = db[COLLECTION_NAME_CHUNK]\n",
    "    out = db.execute(\n",
    "        collection.like(\n",
    "            Document({CHUNK_OUTPUT_KEY: query}),\n",
    "            vector_index=VECTOR_INDEX_IDENTIFIER,\n",
    "            n=top_k,\n",
    "        ).select({})\n",
    "    )\n",
    "\n",
    "    if out:\n",
    "        out = sorted(out, key=lambda x: x['score'], reverse=True)\n",
    "    for r in out:\n",
    "        score = r[\"score\"]\n",
    "        # chunk_data = r.outputs(\"elements\", \"chunk\")\n",
    "        chunk_data = r[upstream_listener.outputs_key] # upstream_listener.outputs_key\n",
    "        metadata = chunk_data[\"metadata\"]\n",
    "        chunk_message = {}\n",
    "        chunk_message[\"score\"] = score\n",
    "        chunk_message[\"metadata\"] = metadata\n",
    "        txt = chunk_data[\"txt\"]\n",
    "        print(txt)\n",
    "        print()\n",
    "        print(chunk_message)\n",
    "        print(\"\\n\\n\", '-' * 20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27ab83ac-cfcc-43b2-9ca3-004415acb0f5",
   "metadata": {},
   "source": [
    "vector_search(\"What is the function of keys 10 to 12 on the left steering wheel keypad?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f15da64e-091c-47ea-9391-aab2a350ffaa",
   "metadata": {},
   "source": "## Define an LLM model Anthropic"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:40:01.930282Z",
     "start_time": "2024-09-06T21:40:00.960573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from superduper_anthropic import AnthropicCompletions\n",
    "MODEL_IDENTIFIER_LLM = \"llm\"\n",
    "# import os\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-api-xxx\"\n",
    "predict_kwargs = {\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.8,\n",
    "}\n",
    "\n",
    "llm = AnthropicCompletions(\n",
    "    identifier=MODEL_IDENTIFIER_LLM,\n",
    "    model='claude-2.1',\n",
    "    predict_kwargs=predict_kwargs\n",
    ")\n",
    "llm.predict(\"Tell me a joke\")"
   ],
   "id": "37d92d03f910d7fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why can't a bicycle stand up by itself? Because it's two-tired!\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:33:42.309706Z",
     "start_time": "2024-09-06T16:33:42.229193Z"
    }
   },
   "cell_type": "code",
   "source": "db.drop(llm)",
   "id": "13b00129bd4b57ad",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:33:45.177855Z",
     "start_time": "2024-09-06T16:33:45.169142Z"
    }
   },
   "cell_type": "code",
   "source": "db.show()",
   "id": "934856709554fe40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define an LLM model OpenAI",
   "id": "edb105e9df37c532"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:31:04.872170Z",
     "start_time": "2024-09-06T21:31:04.242902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from superduper_openai import OpenAIChatCompletion\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = 'sk-prox-xxx'\n",
    "llm = OpenAIChatCompletion(identifier='llm', model='gpt-3.5-turbo')        \n",
    "llm.predict(\"Tell me a joke\")\n"
   ],
   "id": "e700513b9a93d921",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle find its way home?\\nBecause it lost its bearings!\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:18:27.738568Z",
     "start_time": "2024-09-06T16:18:26.656249Z"
    }
   },
   "cell_type": "code",
   "source": "print(db.load(\"model\",\"llm\").predict(\"Tell me a joke\"))",
   "id": "32df3a002d234051",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why can't a bicycle stand up by itself? Because it's two-tired!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate Questions ",
   "id": "a7232ac96cbc9a7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:32:47.319141Z",
     "start_time": "2024-09-06T21:32:45.432586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generate_template = \"\"\"\n",
    "Based on the information provided, please formulate one question related to the document excerpt. Answer in JSON format.\n",
    "\n",
    "**Context**:\n",
    "{%s}\n",
    "\n",
    "Using the information above, generate your questions. Your question can be one of the following types: What, Why, When, Where, Who, How. Please respond in the following format:\n",
    "\n",
    " \n",
    "{\n",
    "  \\\"question_type\\\": \\\"Type of question, e.g., 'What'\\\",\n",
    "  \\\"question\\\": \\\"Your question \\\",\n",
    "}\n",
    "\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "text =\"\"\"\n",
    "The automatic activation of I-Roll that takes places when cruise control is active cannot be switched off. You can however disengage I-Roll so that it is not activated automatically when cruise control is not active.\n",
    "To temporarily disengage I-Roll, press and hold the minus (-) button on the gear selector.\n",
    "To engage I-Roll again, gently depress the accelerator pedal.\n",
    "I-See\n",
    "I-See is a set of functions that use information about the road topography ahead of the truck to optimise the gear selection and, as a result, save fuel. It lowers the fuel consumption and\n",
    "Gearbox\n",
    "improves the driveability when cruise control is active.\n",
    "When you drive with cruise control active on a road, a sensor records the road topography. The recorded information is combined with geographical coordinates from the truck's GPS system. The data are saved, either in the system's memory or in an external topography database (via mobile network).\n",
    "I-See uses these data to save fuel. When you drive with cruise control active on a road, for which data are available, I-See receives the data and can predict when hills and crests will appear. I-See automatically adapts throttle application, gear strategies and truck speed for more fuel efficient driving.\n",
    "Activating I-See\n",
    "\"\"\"\n",
    "# llm_qna=db.load(\"model\",\"llm\")\n",
    "prompt = lambda x: generate_template % x\n",
    "res=llm.predict(prompt(text))\n",
    "# print(prompt(text))"
   ],
   "id": "2eafeae3c6cd6672",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:37:28.787492Z",
     "start_time": "2024-09-06T21:37:28.779746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    out=eval(res)\n",
    "except (SyntaxError, NameError, TypeError, ZeroDivisionError):\n",
    "    out=res.split(\"\\n\",2)[2]\n",
    "    pass\n",
    "eval(res)"
   ],
   "id": "bbd605f5bbcb9913",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[1;32m~/PycharmProjects/poc-volvo/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001B[0m in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0;36m  Cell \u001B[0;32mIn[53], line 6\u001B[0;36m\n\u001B[0;31m    eval(res)\u001B[0;36m\n",
      "\u001B[0;36m  File \u001B[0;32m<string>:1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Here is a possible question based on the context provided:\u001B[0m\n\u001B[0m              ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:40:14.991784Z",
     "start_time": "2024-09-06T21:40:14.987618Z"
    }
   },
   "cell_type": "code",
   "source": "print(res)",
   "id": "b0997acc22f25bbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a possible question based on the context provided:\n",
      "\n",
      "{\n",
      "  \"question_type\": \"What\", \n",
      "  \"question\": \"What does I-Roll do when cruise control is active?\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "b8f8571b-c7f2-489b-a36c-a8ef141bdaa5",
   "metadata": {},
   "source": [
    "MODEL_IDENTIFIER_LLM = \"llm\"\n",
    "prompt_template = (\n",
    "    \"The following is a document and question about the volvo user manual\\n\"\n",
    "    \"Only provide a very concise answer\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Here's the question:{input}\\n\"\n",
    "    \"answer:\"\n",
    ")\n",
    "\n",
    "# from superduper.ext.vllm import VllmModel\n",
    "from superduper_vllm import VllmModel\n",
    "from superduper.ext.openai import OpenAIChatCompletion\n",
    "\n",
    "# llm = VllmModel(\n",
    "#     identifier=MODEL_IDENTIFIER_LLM,\n",
    "#     model_name=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n",
    "#     prompt_func=prompt_template,\n",
    "#     vllm_kwargs={ \n",
    "#         \"gpu_memory_utilization\": 0.50,\n",
    "#         \"max_model_len\": 2048,\n",
    "#         \"quantization\": \"awq\"\n",
    "#                    },\n",
    "#     predict_kwargs={\"max_tokens\": 1024, \"temperature\": 0.8},\n",
    "# )\n",
    "# Add the llm instance\n",
    "\n",
    "# db.apply(llm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompt Template for LLM",
   "id": "78130647a0c0f4d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt_template = (\n",
    "    \"The following is a document and question about the volvo user manual\\n\"\n",
    "    \"Only provide a very concise answer\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Here's the question:{input}\\n\"\n",
    "    \"answer:\"\n",
    ")\n",
    "\n",
    "# @model\n",
    "def build_prompt(query, docs):\n",
    "    # print(docs)\n",
    "    chunks = [doc[\"text\"][\"txt\"] for doc in docs]\n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "    # context=\"blah\"\n",
    "    prompt = prompt_template.format(context=context, input=query)\n",
    "    return prompt"
   ],
   "id": "5f721ef29be84707",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Prompt with documents from vector search output",
   "id": "eba325e9baaa06b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from superduper.components.model import QueryModel\n",
    "item = {'_outputs.chunker.txt': '<var:query>'}\n",
    "top_k = 3\n",
    "vector_search_model = QueryModel(\n",
    "    identifier=\"VectorSearch\",\n",
    "    select=chunk_collection.like(\n",
    "        item, \n",
    "        vector_index=VECTOR_INDEX_IDENTIFIER, \n",
    "        n=top_k\n",
    "    ).select(),\n",
    "    # The _source is the identifier of the upstream data, which can be used to locate the data from upstream sources using `_source`.\n",
    "    postprocess=lambda docs: [{\"text\": doc['_outputs.chunker'], \"_source\": doc[\"_source\"],\"score\": doc[\"score\"]} for doc in docs],\n",
    "    db=db\n",
    ")"
   ],
   "id": "d44ac558016151bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Vector Search Model",
   "id": "bb39028214121d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query=\"What is the function of keys 10 to 12 on the left steering wheel keypad?\"\n",
    "pprint(vector_search_model.predict(query=query))"
   ],
   "id": "d71b58a4de99cf8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query=\"What is the function of keys 10 to 12 on the left steering wheel keypad?\"\n",
    "docs=vector_search_model.predict(query=query)\n",
    "type(docs[0])\n",
    "print(len(docs))\n",
    "prompt=build_prompt(query,docs)"
   ],
   "id": "4ae682e4a2193c8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(db.load(\"model\",\"llm\").predict(prompt))",
   "id": "c80fb8975e5d4842",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define a QA function",
   "id": "700a2fe504358ed6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from superduper.components.model import QueryModel\n",
    "\n",
    "def qa(query, vector_search_top_k=5):\n",
    "    item = {'_outputs.chunker.txt': '<var:query>'}\n",
    "    vector_search_model = QueryModel(\n",
    "        identifier=\"VectorSearch\",\n",
    "        select=chunk_collection.like(\n",
    "            item, \n",
    "            vector_index=VECTOR_INDEX_IDENTIFIER, \n",
    "            n=vector_search_top_k\n",
    "        ).select(),\n",
    "        postprocess=lambda docs: [{\"text\": doc['_outputs.chunker'], \"_source\": doc[\"_source\"],\"score\": doc[\"score\"]} for doc in docs],\n",
    "        db=db\n",
    "    )\n",
    "    out=vector_search_model.predict(query=query)\n",
    "    if out:\n",
    "        out = sorted(out, key=lambda x: x[\"score\"], reverse=True)\n",
    "        prompt= build_prompt(query,out)\n",
    "        output = db.load(\"model\",\"llm\").predict(prompt)\n",
    "    page_messages = []\n",
    "    for source in out:\n",
    "        chunk_data = source['text'] # upstream_listener.outputs_key\n",
    "        metadata = chunk_data[\"metadata\"]\n",
    "        page_number = metadata[\"page_number\"]\n",
    "        points = metadata[\"points\"]\n",
    "        score = source[\"score\"]\n",
    "        page_messages.append(\n",
    "            {\"page_number\": page_number, \"points\": points, \"score\": score}\n",
    "        )\n",
    "    df = pd.DataFrame(page_messages)\n",
    "    display(output)\n",
    "    display(df)\n",
    "    "
   ],
   "id": "9f4732852621675f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query=\"What is the function of keys 10 to 12 on the left steering wheel keypad?\"\n",
    "qa(query, vector_search_top_k=5)"
   ],
   "id": "79cad1514fc97843",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0370eb34-25fa-4d20-91a5-cea4b834df99",
   "metadata": {},
   "source": "## Define a QA function (Legacy)"
  },
  {
   "cell_type": "code",
   "id": "b9af14cc-b878-43d4-8cba-eab8786d2186",
   "metadata": {},
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "def qa(query, vector_search_top_k=5):\n",
    "    collection = db[COLLECTION_NAME_CHUNK]\n",
    "    output, out = db.execute(\n",
    "        model_name=MODEL_IDENTIFIER_LLM,\n",
    "        query=query,\n",
    "        context_select=collection.like(\n",
    "            Document({CHUNK_OUTPUT_KEY: query}),\n",
    "            vector_index=VECTOR_INDEX_IDENTIFIER,\n",
    "            n=vector_search_top_k,\n",
    "        ).select({}),\n",
    "        context_key=f\"{CHUNK_OUTPUT_KEY}.0.txt\",\n",
    "    )\n",
    "    if out:\n",
    "        out = sorted(out, key=lambda x: x[\"score\"], reverse=True)\n",
    "    page_messages = []\n",
    "    for source in out:\n",
    "        chunk_data = source.outputs(\"elements\", \"chunk\")\n",
    "        metadata = chunk_data[\"metadata\"]\n",
    "        page_number = metadata[\"page_number\"]\n",
    "        points = metadata[\"points\"]\n",
    "        score = source[\"score\"]\n",
    "        page_messages.append(\n",
    "            {\"page_number\": page_number, \"points\": points, \"score\": score}\n",
    "        )\n",
    "    df = pd.DataFrame(page_messages)\n",
    "    display(output.content)\n",
    "    display(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e7dd526-fb6f-4363-bdb4-25aac843e3e8",
   "metadata": {},
   "source": "qa(\"What is the function of keys 10 to 12 on the left steering wheel keypad?\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
